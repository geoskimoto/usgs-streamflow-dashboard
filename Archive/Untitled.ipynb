{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6144783-b20d-4820-8105-204d01bd7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "import pandas as pd\n",
    "def get_USGS_data(file_format='json', sites='09380000', start_date='2010-10-01', end_date='2023-10-01', site_status='all'):\n",
    "    server = 'https://waterservices.usgs.gov'\n",
    "    endpoint = '/nwis/dv'\n",
    "    file_format = f'/?format={file_format}'\n",
    "    sites = f'&sites={sites}'\n",
    "    start_date = f'&startDT={start_date}'\n",
    "    end_date = f'&endDT={end_date}'\n",
    "    site_status = f'&siteStatus={site_status}'\n",
    "    \n",
    "    url = f'{server}{endpoint}{file_format}{sites}{start_date}{end_date}{site_status}'\n",
    "    print(url)\n",
    "    req = requests.get(url)\n",
    "        #Correct url for reference:\n",
    "        #'https://waterservices.usgs.gov/nwis/dv/?format=json&sites=09380000&startDT=1921-10-01&endDT=2023-10-01&siteStatus=all'\n",
    "    \n",
    "    if req.ok:\n",
    "        df = pd.DataFrame.from_dict(pd.DataFrame(req.json()['value']['timeSeries'][0]['values'][0]['value']))\n",
    "        # df.set_index('dateTime', inplace=True)\n",
    "        return req, df\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0ce07cc9-4e94-4372-8c4e-b6cb48eb36fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------This module creates customized StackedLinePlots.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#import os\n",
    "#import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import calendar\n",
    "from scipy.integrate import trapz\n",
    "from collections import OrderedDict\n",
    "\n",
    "class StackedLinePlotOriginal:\n",
    "    def __init__(self, data, name_of_date_column, name_of_Q_column):\n",
    "        \n",
    "        # self.csv_path = data\n",
    "        self._df = data.copy()  # Initialize to None\n",
    "        self.name_of_date_column = name_of_date_column  # Store the column name\n",
    "        self.name_of_Q_column = name_of_Q_column  # Store the column name\n",
    "        self._df['Date'] = pd.to_datetime(self._df[self.name_of_date_column])\n",
    "        self._df['month'] = self._df['Date'].dt.month\n",
    "        self._df['Year'] = self._df['Date'].dt.year\n",
    "        self._df['month-day'] = self._df['Date'].apply(lambda x: x.strftime('%m-%d'))\n",
    "        \n",
    "        self._pivot_table = None\n",
    "        self._name_of_Q_column = name_of_Q_column\n",
    "        self._forced_x_positions = None\n",
    "        self._forced_x_labels = None\n",
    "        self._mean = None\n",
    "        self._median = None\n",
    "        self._st_dev = None\n",
    "        self._lower_bound = None\n",
    "        self._upper_bound = None\n",
    "        self._lower_bound_percentile25 = None\n",
    "        self._upper_bound_percentile75 = None\n",
    "        self._colors = ['crimson', 'springgreen', 'dodgerblue', 'purple', 'green', 'deeppink', 'lawngreen', 'coral', 'lime', 'navy', 'goldenrod']\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "\n",
    "    @df.setter\n",
    "    def df(self, data):\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            print(\"Data is a dataframe.\")\n",
    "            self._df = data.copy()  # Set the DataFrame directly\n",
    "        elif isinstance(data, str):\n",
    "            try:\n",
    "                print(\"csv\")\n",
    "                self._df = pd.read_csv(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading CSV file: {e}\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"Invalid input type. Please provide either a pandas DataFrame or a CSV file path.\")\n",
    "            return\n",
    "        self._df['Date'] = pd.to_datetime(self._df[self.name_of_date_column])\n",
    "        self._df['month'] = self._df['Date'].dt.month\n",
    "        self._df['Year'] = self._df['Date'].dt.year\n",
    "        self._df['month-day'] = self._df['Date'].apply(lambda x: x.strftime('%m-%d'))\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def mean_value(self):\n",
    "        if self._mean_value is None:\n",
    "            self.calculate_statistics()\n",
    "        return self._mean_value\n",
    "\n",
    "    @property\n",
    "    def monthly_stats(self):\n",
    "        monthly_stats = self._monthly_stats\n",
    "        monthly_stats.index = monthly_stats.index.map(lambda x: calendar.month_name[x])\n",
    "        monthly_stats = monthly_stats.round(1)\n",
    "        return monthly_stats\n",
    "\n",
    "    @property\n",
    "    def stats(self):\n",
    "        return self._df_stat_summary.round(2)\n",
    "\n",
    "    def calculate_statistics(self):\n",
    "        self._stats = self._df.groupby(\"month-day\")[self._name_of_Q_column].agg(['mean','median', 'std', (\"q25\", lambda x: x.quantile(0.25)),(\"q75\", lambda y: y.quantile(0.75))])\n",
    "        self._monthly_stats = self._df.groupby(\"month\")[self._name_of_Q_column].agg(['mean','median', 'std', (\"q25\", lambda x: x.quantile(0.25)),(\"q75\", lambda y: y.quantile(0.75))])\n",
    "        self._pivot_table = self._df.pivot(index=\"month-day\", columns='Year', values=self._name_of_Q_column)\n",
    "        self._mean = self._stats.iloc[:,0]\n",
    "        self._median = self._stats.iloc[:,1]\n",
    "        self._st_dev = self._stats.iloc[:,2]\n",
    "        self._percentile25 = self._stats.iloc[:,3]\n",
    "        self._percentile75 = self._stats.iloc[:,4]\n",
    "        self._lower_bound = self._mean - self._st_dev\n",
    "        self._upper_bound = self._mean + self._st_dev\n",
    "        self._lower_bound_percentile25 = self._mean - self._percentile25\n",
    "        self._upper_bound_percentile75 = self._mean + self._percentile75\n",
    "\n",
    "    def calculate_yearly_volumes(self):\n",
    "        years = []\n",
    "        area = []\n",
    "        for year in self._pivot_table.columns:\n",
    "            dates = (list(range(0, len(self._pivot_table[year].dropna()))))\n",
    "            area.append(trapz(self._pivot_table[year].dropna(), dates))\n",
    "            years.append(year)\n",
    "        area_dict = OrderedDict()\n",
    "        for key, value in zip(years, area):\n",
    "            area_dict[key] = value\n",
    "        return area_dict\n",
    "\n",
    "    def plotStackedLinePlot(self, forced_x_positions=[1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 336],\n",
    "                             forced_x_labels=['01-01', '02-01', '03-01', '04-01', '05-01', '06-01', '07-01', '08-01', '09-01', '10-01', '11-01', '12-01'],\n",
    "                             title=None, highlight_years=[2001, 2015, 2023], plot_central_tendency_stats=True,\n",
    "                             quartile_shading=True, quartile_shading_alpha=0.4, quartile_shading_zorder=1,\n",
    "                             series_labels=True, series_alpha=1, group_by_decade=False, decade_stats_to_plot=\"All\",\n",
    "                             y_lower_lim=0, y_upper_lim=\"True\", legend='upper right', legend_ncol=1,\n",
    "                             input_start_year=2010, input_end_year=2020):\n",
    "\n",
    "        # if y_upper_lim == \"Auto\":\n",
    "        #     y_upper_lim = self._ylim_max\n",
    "\n",
    "        self._df = self._df[(self._df['Year'] >= input_start_year) & (self._df['Year'] <= input_end_year)]\n",
    "        self._unique_years = list(self._df['Year'].unique())\n",
    "        self._start_year = self._unique_years[0]\n",
    "        self._end_year = self._unique_years[-1]\n",
    "        self._num_of_decades = math.ceil((self._end_year - self._start_year) / 10)\n",
    "        self._unique_decades = list(self._df['Year'].apply(lambda year: (year // 10) * 10).unique())\n",
    "        self._forced_x_positions = forced_x_positions\n",
    "        self._forced_x_labels = forced_x_labels\n",
    "        self.input_start_year = input_start_year\n",
    "        self.input_end_year = input_end_year\n",
    "        self.calculate_statistics()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(9, 7))\n",
    "\n",
    "        if plot_central_tendency_stats == True:\n",
    "            self._mean.plot(ax=ax, label=\"Mean\", linestyle=':', color='black', linewidth=1.5, zorder=3)\n",
    "            self._median.plot(ax=ax, label=\"Median\", linestyle=':', color='red', linewidth=1.5, zorder=3)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if highlight_years:\n",
    "            for i, year in enumerate(highlight_years):\n",
    "                self._pivot_table.loc[:, year].plot(ax=ax, linewidth=1.6, zorder=3, color=self._colors[i])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if quartile_shading == True:\n",
    "            plt.fill_between(\n",
    "                list(range(0, len(pd.DataFrame(self._mean).iloc[:, 0]))),\n",
    "                pd.DataFrame(self._mean).iloc[:, 0].astype(float),\n",
    "                pd.DataFrame(self._lower_bound).iloc[:, 0].astype(float),\n",
    "                where=(pd.DataFrame(self._mean).iloc[:, 0].astype(float) > pd.DataFrame(self._lower_bound_percentile25).iloc[:, 0].astype(float)),\n",
    "                interpolate=True, color='yellow', alpha=quartile_shading_alpha, zorder=quartile_shading_zorder, label=\"q25-q75\")\n",
    "\n",
    "            plt.fill_between(\n",
    "                list(range(0, len(pd.DataFrame(self._mean).iloc[:, 0]))),\n",
    "                pd.DataFrame(self._mean).iloc[:, 0].astype(float),\n",
    "                pd.DataFrame(self._upper_bound).iloc[:, 0].astype(float),\n",
    "                where=(pd.DataFrame(self._mean).iloc[:, 0].astype(float) < pd.DataFrame(self._upper_bound_percentile75).iloc[:, 0].astype(float)),\n",
    "                interpolate=True, color='yellow', alpha=quartile_shading_alpha, zorder=1)\n",
    "\n",
    "        if group_by_decade == True:\n",
    "            decade_groups = []\n",
    "\n",
    "            for i in self._unique_decades:\n",
    "                decade_groups.append(list(range(i, i + 10)))\n",
    "\n",
    "            if len(decade_groups) == 1:\n",
    "                start_year_index = decade_groups[0].index(self.input_start_year)\n",
    "                end_year_index = decade_groups[0].index(self.input_end_year)\n",
    "                decade_groups[0] = decade_groups[0][start_year_index:end_year_index + 1]\n",
    "            else:\n",
    "                start_year_index = decade_groups[0].index(self.input_start_year)\n",
    "                decade_groups[0] = decade_groups[0][start_year_index:]\n",
    "\n",
    "                end_group = list(range(decade_groups[-1][0], self.input_end_year + 1))\n",
    "                decade_groups[-1] = end_group\n",
    "\n",
    "            colors = ['blue', 'orange', 'purple', 'red']\n",
    "            for i, decade in enumerate(decade_groups):\n",
    "                decadeDF = self._pivot_table.loc[:, decade]\n",
    "                means = decadeDF[decadeDF.columns].mean(axis=1)\n",
    "                medians = decadeDF[decadeDF.columns].median(axis=1)\n",
    "                if decade_stats_to_plot == 'mean':\n",
    "                    means.plot(ax=ax, linestyle=\"--\", label=\"mean {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "                elif decade_stats_to_plot == 'median':\n",
    "                    medians.plot(ax=ax, linestyle=\"-.\", label=\"median {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "                else:\n",
    "                    means.plot(ax=ax, linestyle=\"--\", label=\"mean {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "                    medians.plot(ax=ax, linestyle=\"-.\", label=\"median {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "\n",
    "        else:\n",
    "            if highlight_years:\n",
    "                filtered_years = [year for year in self._pivot_table.columns if year not in highlight_years]\n",
    "                filtered_pivot_table = self._pivot_table.loc[:, filtered_years]\n",
    "            else:\n",
    "                filtered_pivot_table = self._pivot_table\n",
    "\n",
    "            if series_labels == False:\n",
    "                for i in filtered_pivot_table.columns:\n",
    "                    filtered_pivot_table[i].plot(ax=ax, alpha=series_alpha, zorder=2, linewidth=1.0, label='')\n",
    "            else:\n",
    "                filtered_pivot_table.plot(ax=ax, alpha=series_alpha, zorder=2, linewidth=1.0, label='')\n",
    "\n",
    "        if self._forced_x_positions is not None and self._forced_x_labels is not None:\n",
    "            ax.set_xticks(self._forced_x_positions)\n",
    "            xlim_min = self._forced_x_positions[0]\n",
    "            xlim_max = self._forced_x_positions[-1]\n",
    "            ax.set_xticklabels(self._forced_x_labels, rotation=45)\n",
    "            ax.set_xlim([xlim_min, xlim_max])\n",
    "            ax.set_ylim([y_lower_lim, y_upper_lim])\n",
    "\n",
    "        plt.grid(color='green', linestyle=\":\", linewidth=0.5)\n",
    "        plt.xlabel('Month-Day')\n",
    "        plt.ylabel('Lake Elevation (ft)')\n",
    "        plt.title(title)\n",
    "\n",
    "        if legend == \"partial\":\n",
    "            plt.legend(loc='upper right', ncol=legend_ncol, labels=['Mean', 'Median'])\n",
    "\n",
    "        else:\n",
    "            plt.legend(loc=legend, ncol=legend_ncol)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"-------This module creates customized StackedLinePlots.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b534e1bb-a581-4209-95f5-5b8da9084bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c4b40a-a477-4786-9b24-e40e364d5361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0117e6d4-9aaa-44f3-a4cd-5243d42fd2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://waterservices.usgs.gov/nwis/dv/?format=json&sites=09380000&startDT=1999-10-01&endDT=2023-10-01&siteStatus=all\n"
     ]
    }
   ],
   "source": [
    "req, df = get_USGS_data(sites='09380000', start_date='1999-10-01', end_date='2023-10-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94908094-32a8-42f9-bcf0-280075e2fd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.set_index('dateTime', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3a8299c-78e7-4400-b377-9454f4b80ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>qualifiers</th>\n",
       "      <th>dateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.9</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-01T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-02T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.2</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-03T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-04T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-05T00:00:00.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  value qualifiers                 dateTime\n",
       "0   9.9        [A]  1999-10-01T00:00:00.000\n",
       "1  10.1        [A]  1999-10-02T00:00:00.000\n",
       "2  10.2        [A]  1999-10-03T00:00:00.000\n",
       "3  10.1        [A]  1999-10-04T00:00:00.000\n",
       "4  10.1        [A]  1999-10-05T00:00:00.000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ec484b4-b20f-484f-ae42-8acd3b8a6a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# req.json()['value']['timeSeries'][0]['values'][0]['value']#.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f225086a-e7df-4f7d-8b2d-8f52c518a475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(req.json()['value']['timeSeries'][0]['values'][0]['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93a03aa-4986-4594-9840-914278e431b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://waterservices.usgs.gov/nwis/dv/?format=json&sites=09380000&startDT=1921-10-01&endDT=2023-10-01&siteStatus=all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37bc5270-c687-420e-90ed-11051b1bd29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "LeesFerry = StackedLinePlotOriginal(df, 'dateTime', 'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "daaffaf7-41e4-49ff-8e75-09fe8b381db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>qualifiers</th>\n",
       "      <th>dateTime</th>\n",
       "      <th>Date</th>\n",
       "      <th>month</th>\n",
       "      <th>Year</th>\n",
       "      <th>month-day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.9</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-01T00:00:00.000</td>\n",
       "      <td>1999-10-01</td>\n",
       "      <td>10</td>\n",
       "      <td>1999</td>\n",
       "      <td>10-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-02T00:00:00.000</td>\n",
       "      <td>1999-10-02</td>\n",
       "      <td>10</td>\n",
       "      <td>1999</td>\n",
       "      <td>10-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  value qualifiers                 dateTime       Date  month  Year month-day\n",
       "0   9.9        [A]  1999-10-01T00:00:00.000 1999-10-01     10  1999     10-01\n",
       "1  10.1        [A]  1999-10-02T00:00:00.000 1999-10-02     10  1999     10-02"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LeesFerry._df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c85acbd9-1065-459e-936f-96064d590155",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Could not convert 10.49.49.28.89.710.09.99.510.29.78.711.09.49.211.110.011.210.99.510.49.68.89.1 to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36marray_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1586\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1587\u001b[1;33m                 result = self.grouper._cython_operation(\n\u001b[0m\u001b[0;32m   1588\u001b[0m                     \u001b[1;34m\"aggregate\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_cython_operation\u001b[1;34m(self, kind, values, how, axis, min_count, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[0mngroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m         return cy_op.cython_operation(\n\u001b[0m\u001b[0;32m    940\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mcython_operation\u001b[1;34m(self, values, axis, min_count, comp_ids, ngroups, **kwargs)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 626\u001b[1;33m         return self._cython_op_ndim_compat(\n\u001b[0m\u001b[0;32m    627\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_cython_op_ndim_compat\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    450\u001b[0m                 \u001b[0mresult_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m             res = self._call_cython_op(\n\u001b[0m\u001b[0;32m    452\u001b[0m                 \u001b[0mvalues2d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_call_cython_op\u001b[1;34m(self, values, min_count, ngroups, comp_ids, mask, result_mask, **kwargs)\u001b[0m\n\u001b[0;32m    515\u001b[0m         \u001b[0mout_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_output_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mngroups\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 516\u001b[1;33m         \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_cython_func_and_vals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    517\u001b[0m         \u001b[0mout_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_out_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36mget_cython_func_and_vals\u001b[1;34m(self, values, is_numeric)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_cython_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_numeric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_get_cython_function\u001b[1;34m(cls, kind, how, dtype, is_numeric)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[1;31m# raise NotImplementedError here rather than TypeError later\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 raise NotImplementedError(\n\u001b[0m\u001b[0;32m    165\u001b[0m                     \u001b[1;34mf\"function is not implemented for this dtype: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: function is not implemented for this dtype: [how->mean,dtype->object]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1621\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1622\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1623\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '10.49.49.28.89.710.09.99.510.29.78.711.09.49.211.110.011.210.99.510.49.68.89.1'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1625\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomplex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: complex() arg is a malformed string",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10752\\3821665671.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLeesFerry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10752\\1905626241.py\u001b[0m in \u001b[0;36mcalculate_statistics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"month-day\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_of_Q_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"q25\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"q75\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_monthly_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"month\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_of_Q_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"q25\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"q75\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pivot_table\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"month-day\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Year'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_of_Q_column\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m             \u001b[1;31m# but not the class list / tuple itself.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_mangle_lambdas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 271\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aggregate_multiple_funcs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    272\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mrelabeling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    273\u001b[0m                 \u001b[1;31m# error: Incompatible types in assignment (expression has type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36m_aggregate_multiple_funcs\u001b[1;34m(self, arg)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutputKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m             \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\generic.py\u001b[0m in \u001b[0;36maggregate\u001b[1;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1963\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numba_agg_general\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msliding_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"groupby_mean\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1964\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1965\u001b[1;33m             result = self._cython_agg_general(\n\u001b[0m\u001b[0;32m   1966\u001b[0m                 \u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1967\u001b[0m                 \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only_bool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_cython_agg_general\u001b[1;34m(self, how, alt, numeric_only, min_count)\u001b[0m\n\u001b[0;32m   1599\u001b[0m         \u001b[1;31m# TypeError -> we may have an exception in trying to aggregate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m         \u001b[1;31m#  continue and exclude the block\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1601\u001b[1;33m         \u001b[0mnew_mgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouped_reduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_failures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_ser\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_mgr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\internals\\base.py\u001b[0m in \u001b[0;36mgrouped_reduce\u001b[1;34m(self, func, ignore_failures)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefault_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36marray_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m   1593\u001b[0m                 \u001b[1;31m# try to python agg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m                 \u001b[1;31m# TODO: shouldn't min_count matter?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1595\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_agg_py_fallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m_agg_py_fallback\u001b[1;34m(self, values, ndim, alt)\u001b[0m\n\u001b[0;32m   1547\u001b[0m         \u001b[1;31m#  should always be preserved by the implemented aggregations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1548\u001b[0m         \u001b[1;31m# TODO: Is this exactly right; see WrappedCythonOp get_result_dtype?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1549\u001b[1;33m         \u001b[0mres_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreserve_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1551\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCategorical\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36magg_series\u001b[1;34m(self, obj, func, preserve_dtype)\u001b[0m\n\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 981\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aggregate_series_pure_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    982\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    983\u001b[0m         \u001b[0mnpvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaybe_convert_objects\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtry_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\ops.py\u001b[0m in \u001b[0;36m_aggregate_series_pure_python\u001b[1;34m(self, obj, func)\u001b[0m\n\u001b[0;32m   1003\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplitter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m             \u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"groupby\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1006\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\groupby\\groupby.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1965\u001b[0m             result = self._cython_agg_general(\n\u001b[0;32m   1966\u001b[0m                 \u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1967\u001b[1;33m                 \u001b[0malt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only_bool\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1968\u001b[0m                 \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only_bool\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1969\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11122\u001b[0m             \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11123\u001b[0m         ):\n\u001b[1;32m> 11124\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  11126\u001b[0m         \u001b[0msetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mmean\u001b[1;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10692\u001b[0m         \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10693\u001b[0m     ) -> Series | float:\n\u001b[1;32m> 10694\u001b[1;33m         return self._stat_function(\n\u001b[0m\u001b[0;32m  10695\u001b[0m             \u001b[1;34m\"mean\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10696\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_stat_function\u001b[1;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  10644\u001b[0m                 \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10645\u001b[0m             )\n\u001b[1;32m> 10646\u001b[1;33m         return self._reduce(\n\u001b[0m\u001b[0;32m  10647\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m  10648\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4469\u001b[0m                 )\n\u001b[0;32m   4470\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4471\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4473\u001b[0m     def _reindex_indexer(\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    153\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 410\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    412\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdatetimelike\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m     \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 698\u001b[1;33m     \u001b[0mthe_sum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    699\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ndim\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_local\\envs\\regression\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_ensure_numeric\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1627\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m                 \u001b[1;31m# e.g. \"foo\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Could not convert {x} to numeric\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Could not convert 10.49.49.28.89.710.09.99.510.29.78.711.09.49.211.110.011.210.99.510.49.68.89.1 to numeric"
     ]
    }
   ],
   "source": [
    "LeesFerry.calculate_statistics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "014a19b3-183a-440b-91a0-4b5288c36828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>qualifiers</th>\n",
       "      <th>dateTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.9</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-01T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.1</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-02T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.2</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-03T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.1</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-04T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.1</td>\n",
       "      <td>[A]</td>\n",
       "      <td>1999-10-05T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8369</th>\n",
       "      <td>17.5</td>\n",
       "      <td>[P]</td>\n",
       "      <td>2023-09-27T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8370</th>\n",
       "      <td>17.5</td>\n",
       "      <td>[P]</td>\n",
       "      <td>2023-09-28T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8371</th>\n",
       "      <td>17.4</td>\n",
       "      <td>[P]</td>\n",
       "      <td>2023-09-29T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8372</th>\n",
       "      <td>17.2</td>\n",
       "      <td>[P]</td>\n",
       "      <td>2023-09-30T00:00:00.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8373</th>\n",
       "      <td>17.0</td>\n",
       "      <td>[P]</td>\n",
       "      <td>2023-10-01T00:00:00.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8374 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     value qualifiers                 dateTime\n",
       "0      9.9        [A]  1999-10-01T00:00:00.000\n",
       "1     10.1        [A]  1999-10-02T00:00:00.000\n",
       "2     10.2        [A]  1999-10-03T00:00:00.000\n",
       "3     10.1        [A]  1999-10-04T00:00:00.000\n",
       "4     10.1        [A]  1999-10-05T00:00:00.000\n",
       "...    ...        ...                      ...\n",
       "8369  17.5        [P]  2023-09-27T00:00:00.000\n",
       "8370  17.5        [P]  2023-09-28T00:00:00.000\n",
       "8371  17.4        [P]  2023-09-29T00:00:00.000\n",
       "8372  17.2        [P]  2023-09-30T00:00:00.000\n",
       "8373  17.0        [P]  2023-10-01T00:00:00.000\n",
       "\n",
       "[8374 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7aa3caa-30ad-45ff-bcf6-5e36d84867fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'groupby'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1328\\2620032407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLeesFerry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalculate_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# LeesFerry.plot_stacked_line_plot()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1328\\3508719886.py\u001b[0m in \u001b[0;36mcalculate_statistics\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcalculate_statistics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"month-day\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_of_Q_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"q25\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"q75\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_monthly_stats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"month\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name_of_Q_column\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'median'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'std'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"q25\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"q75\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'groupby'"
     ]
    }
   ],
   "source": [
    "LeesFerry.calculate_statistics()\n",
    "# LeesFerry.plot_stacked_line_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda3c8a5-0a1c-40ed-ba9c-62dc67157f95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d027e30-5bcc-4950-b401-693283c38cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import calendar\n",
    "from scipy.integrate import trapz\n",
    "from collections import OrderedDict\n",
    "\n",
    "class StackedLinePlot:\n",
    "    def __init__(self, data, date_column_name, q_column_name):\n",
    "        \n",
    "        \n",
    "        self.csv_path = data\n",
    "        self._df = None\n",
    "        # self._date_column_name = date_column_name\n",
    "        # self._q_column_name = q_column_name\n",
    "        \n",
    "        self._pivot_table = None\n",
    "        self._name_of_Q_column = q_column_name\n",
    "        self._forced_x_positions = None\n",
    "        self._forced_x_labels = None\n",
    "        self._mean = None\n",
    "        self._median = None\n",
    "        self._st_dev = None\n",
    "        self._lower_bound = None\n",
    "        self._upper_bound = None\n",
    "        self._lower_bound_percentile25 = None\n",
    "        self._upper_bound_percentile75 = None\n",
    "        self._colors = ['crimson', 'springgreen', 'dodgerblue', 'purple', 'green', 'deeppink', 'lawngreen', 'coral', 'lime', 'navy', 'goldenrod']\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "\n",
    "    @df.setter\n",
    "    def df(self, data):\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            self._df = data  # Set the DataFrame directly\n",
    "        elif isinstance(data, str):\n",
    "            try:\n",
    "                self._df = pd.read_csv(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading CSV file: {e}\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"Invalid input type. Please provide either a pandas DataFrame or a CSV file path.\")\n",
    "            return\n",
    "        self._df['Date'] = pd.to_datetime(self._df[date_column_name])\n",
    "        self._df['month'] = self._df['Date'].dt.month\n",
    "        self._df['Year'] = self._df['Date'].dt.year\n",
    "        self._df['month-day'] = self._df['Date'].apply(lambda x: x.strftime('%m-%d'))\n",
    "    #     try:\n",
    "    #         self._df = pd.read_csv(csv_path)\n",
    "    #         self._create_pivot_table()\n",
    "    #     except Exception as e:\n",
    "    #         print(e)\n",
    "\n",
    "    def _create_pivot_table(self):\n",
    "        if self._df is not None:\n",
    "            self._pivot_table = self._df.pivot(index=\"month-day\", columns='Year', values=self._name_of_Q_column)\n",
    "\n",
    "    @property\n",
    "    def mean_value(self):\n",
    "        if self._mean is None:\n",
    "            self.calculate_statistics()\n",
    "        return self._mean\n",
    "\n",
    "    @property\n",
    "    def monthly_stats(self):\n",
    "        monthly_stats = self._monthly_stats\n",
    "        monthly_stats.index = monthly_stats.index.map(lambda x: calendar.month_name[x])\n",
    "        monthly_stats = monthly_stats.round(1)\n",
    "        return monthly_stats\n",
    "\n",
    "    @property\n",
    "    def stats(self):\n",
    "        return self._df.describe().round(2)\n",
    "\n",
    "\n",
    "\n",
    "    def calculate_statistics(self):\n",
    "        self._stats = self._df.groupby(\"month-day\")[self._name_of_Q_column].agg(['mean','median', 'std', (\"q25\", lambda x: x.quantile(0.25)),(\"q75\", lambda y: y.quantile(0.75))])\n",
    "        self._monthly_stats = self._df.groupby(\"month\")[self._name_of_Q_column].agg(['mean','median', 'std', (\"q25\", lambda x: x.quantile(0.25)),(\"q75\", lambda y: y.quantile(0.75))])\n",
    "        self._mean = self._stats.iloc[:,0]\n",
    "        self._median = self._stats.iloc[:,1]\n",
    "        self._st_dev = self._stats.iloc[:,2]\n",
    "        self._percentile25 = self._stats.iloc[:,3]\n",
    "        self._percentile75 = self._stats.iloc[:,4]\n",
    "        self._lower_bound = self._mean - self._st_dev\n",
    "        self._upper_bound = self._mean + self._st_dev\n",
    "        self._lower_bound_percentile25 = self._mean - self._percentile25\n",
    "        self._upper_bound_percentile75 = self._mean + self._percentile75\n",
    "\n",
    "    def calculate_yearly_volumes(self):\n",
    "        years = []\n",
    "        area = []\n",
    "        for year in self._pivot_table.columns:\n",
    "            dates = (list(range(0, len(self._pivot_table[year].dropna()))))\n",
    "            area.append(trapz(self._pivot_table[year].dropna(), dates))\n",
    "            years.append(year)\n",
    "        area_dict = OrderedDict()\n",
    "        for key, value in zip(years, area):\n",
    "            area_dict[key] = value\n",
    "        return area_dict\n",
    "\n",
    "    def plotStackedLinePlot(self, forced_x_positions=[1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 336],\n",
    "                             forced_x_labels=['01-01', '02-01', '03-01', '04-01', '05-01', '06-01', '07-01', '08-01', '09-01', '10-01', '11-01', '12-01'],\n",
    "                             title=None, highlight_years=[2001, 2015, 2023], plot_central_tendency_stats=True,\n",
    "                             quartile_shading=True, quartile_shading_alpha=0.4, quartile_shading_zorder=1,\n",
    "                             series_labels=True, series_alpha=1, group_by_decade=False, decade_stats_to_plot=\"All\",\n",
    "                             y_lower_lim=0, y_upper_lim=\"True\", legend='upper right', legend_ncol=1,\n",
    "                             input_start_year=2010, input_end_year=2020):\n",
    "\n",
    "        # if y_upper_lim == \"Auto\":\n",
    "        #     y_upper_lim = self._ylim_max\n",
    "\n",
    "        self._df = self._df[(self._df['Year'] >= input_start_year) & (self._df['Year'] <= input_end_year)]\n",
    "        self._unique_years = list(self._df['Year'].unique())\n",
    "        self._start_year = self._unique_years[0]\n",
    "        self._end_year = self._unique_years[-1]\n",
    "        self._num_of_decades = math.ceil((self._end_year - self._start_year) / 10)\n",
    "        self._unique_decades = list(self._df['Year'].apply(lambda year: (year // 10) * 10).unique())\n",
    "        self._forced_x_positions = forced_x_positions\n",
    "        self._forced_x_labels = forced_x_labels\n",
    "        self.input_start_year = input_start_year\n",
    "        self.input_end_year = input_end_year\n",
    "        self.calculate_statistics()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(9, 7))\n",
    "\n",
    "        if plot_central_tendency_stats == True:\n",
    "            self._mean.plot(ax=ax, label=\"Mean\", linestyle=':', color='black', linewidth=1.5, zorder=3)\n",
    "            self._median.plot(ax=ax, label=\"Median\", linestyle=':', color='red', linewidth=1.5, zorder=3)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if highlight_years:\n",
    "            for i, year in enumerate(highlight_years):\n",
    "                self._pivot_table.loc[:, year].plot(ax=ax, linewidth=1.6, zorder=3, color=self._colors[i])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if quartile_shading == True:\n",
    "            plt.fill_between(\n",
    "                list(range(0, len(pd.DataFrame(self._mean).iloc[:, 0]))),\n",
    "                pd.DataFrame(self._mean).iloc[:, 0].astype(float),\n",
    "                pd.DataFrame(self._lower_bound).iloc[:, 0].astype(float),\n",
    "                where=(pd.DataFrame(self._mean).iloc[:, 0].astype(float) > pd.DataFrame(self._lower_bound_percentile25).iloc[:, 0].astype(float)),\n",
    "                interpolate=True, color='yellow', alpha=quartile_shading_alpha, zorder=quartile_shading_zorder, label=\"q25-q75\")\n",
    "\n",
    "            plt.fill_between(\n",
    "                list(range(0, len(pd.DataFrame(self._mean).iloc[:, 0]))),\n",
    "                pd.DataFrame(self._mean).iloc[:, 0].astype(float),\n",
    "                pd.DataFrame(self._upper_bound).iloc[:, 0].astype(float),\n",
    "                where=(pd.DataFrame(self._mean).iloc[:, 0].astype(float) < pd.DataFrame(self._upper_bound_percentile75).iloc[:, 0].astype(float)),\n",
    "                interpolate=True, color='yellow', alpha=quartile_shading_alpha, zorder=1)\n",
    "\n",
    "        if group_by_decade == True:\n",
    "            decade_groups = []\n",
    "\n",
    "            for i in self._unique_decades:\n",
    "                decade_groups.append(list(range(i, i + 10)))\n",
    "\n",
    "            if len(decade_groups) == 1:\n",
    "                start_year_index = decade_groups[0].index(self.input_start_year)\n",
    "                end_year_index = decade_groups[0].index(self.input_end_year)\n",
    "                decade_groups[0] = decade_groups[0][start_year_index:end_year_index + 1]\n",
    "            else:\n",
    "                start_year_index = decade_groups[0].index(self.input_start_year)\n",
    "                decade_groups[0] = decade_groups[0][start_year_index:]\n",
    "\n",
    "                end_group = list(range(decade_groups[-1][0], self.input_end_year + 1))\n",
    "                decade_groups[-1] = end_group\n",
    "\n",
    "            colors = ['blue', 'orange', 'purple', 'red']\n",
    "            for i, decade in enumerate(decade_groups):\n",
    "                decadeDF = self._pivot_table.loc[:, decade]\n",
    "                means = decadeDF[decadeDF.columns].mean(axis=1)\n",
    "                medians = decadeDF[decadeDF.columns].median(axis=1)\n",
    "                if decade_stats_to_plot == 'mean':\n",
    "                    means.plot(ax=ax, linestyle=\"--\", label=\"mean {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "                elif decade_stats_to_plot == 'median':\n",
    "                    medians.plot(ax=ax, linestyle=\"-.\", label=\"median {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "                else:\n",
    "                    means.plot(ax=ax, linestyle=\"--\", label=\"mean {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "                    medians.plot(ax=ax, linestyle=\"-.\", label=\"median {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "\n",
    "        else:\n",
    "            if highlight_years:\n",
    "                filtered_years = [year for year in self._pivot_table.columns if year not in highlight_years]\n",
    "                filtered_pivot_table = self._pivot_table.loc[:, filtered_years]\n",
    "            else:\n",
    "                filtered_pivot_table = self._pivot_table\n",
    "\n",
    "            if series_labels == False:\n",
    "                for i in filtered_pivot_table.columns:\n",
    "                    filtered_pivot_table[i].plot(ax=ax, alpha=series_alpha, zorder=2, linewidth=1.0, label='')\n",
    "            else:\n",
    "                filtered_pivot_table.plot(ax=ax, alpha=series_alpha, zorder=2, linewidth=1.0, label='')\n",
    "\n",
    "        if self._forced_x_positions is not None and self._forced_x_labels is not None:\n",
    "            ax.set_xticks(self._forced_x_positions)\n",
    "            xlim_min = self._forced_x_positions[0]\n",
    "            xlim_max = self._forced_x_positions[-1]\n",
    "            ax.set_xticklabels(self._forced_x_labels, rotation=45)\n",
    "            ax.set_xlim([xlim_min, xlim_max])\n",
    "            ax.set_ylim([y_lower_lim, y_upper_lim])\n",
    "\n",
    "        plt.grid(color='green', linestyle=\":\", linewidth=0.5)\n",
    "        plt.xlabel('Month-Day')\n",
    "        plt.ylabel('Lake Elevation (ft)')\n",
    "        plt.title(title)\n",
    "\n",
    "        if legend == \"partial\":\n",
    "            plt.legend(loc='upper right', ncol=legend_ncol, labels=['Mean', 'Median'])\n",
    "\n",
    "        else:\n",
    "            plt.legend(loc=legend, ncol=legend_ncol)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "            # def calculate_statistics(self):\n",
    "#         self._stats = self._df.groupby(\"month-day\")[self._name_of_Q_column].agg(['mean', 'median', 'std', (\"q25\", lambda x: x.quantile(0.25)), (\"q75\", lambda y: y.quantile(0.75))])\n",
    "#         self._monthly_stats = self._df.groupby(\"month\")[self._name_of_Q_column].agg(['mean', 'median', 'std', (\"q25\", lambda x: x.quantile(0.25)), (\"q75\", lambda y: y.quantile(0.75))])\n",
    "#         self._mean = self._stats.iloc[:, 0]\n",
    "#         self._median = self._stats.iloc[:, 1]\n",
    "#         self._st_dev = self._stats.iloc[:, 2]\n",
    "#         self._percentile25 = self._stats.iloc[:, 3]\n",
    "#         self._percentile75 = self._stats.iloc[:, 4]\n",
    "#         self._lower_bound = self._mean - self._st_dev\n",
    "#         self._upper_bound = self._mean + self._st_dev\n",
    "#         self._lower_bound_percentile25 = self._mean - self._percentile25\n",
    "#         self._upper_bound_percentile75 = self._mean + self._percentile75\n",
    "   \n",
    "\n",
    "#     def calculate_yearly_volumes(self):\n",
    "#         years = []\n",
    "#         area = []\n",
    "#         for year in self._pivot_table.columns:\n",
    "#             dates = (list(range(0,len(self._pivot_table[year].dropna()))))\n",
    "#             area.append(trapz(self._pivot_table[year].dropna(), dates))\n",
    "#             years.append(year)\n",
    " \n",
    "#         Area_dict = OrderedDict()\n",
    "#         for key, value in zip(years, area):\n",
    "#             Area_dict[key] = value\n",
    "\n",
    " \n",
    "\n",
    "# #        Area_df = pd.DataFrame(dict(zip(years,area)))\n",
    "# #       \n",
    "# #        Area_df = pd.DataFrame(Area_dict)\n",
    "# #        area = {str(year): trapz(self._pivot_table[year].dropna(), list(range(0,len(self._pivot_table[year].dropna())))) for year in self._pivot_table.columns}\n",
    "# #        self._area_df = pd.DataFrame(area)\n",
    "#         return Area_dict\n",
    "\n",
    "     \n",
    "\n",
    "#     def plot_stacked_line_plot(\n",
    "#         self,\n",
    "#         forced_x_positions=[1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 336],\n",
    "#         forced_x_labels=['01-01', '02-01', '03-01', '04-01', '05-01', '06-01', '07-01', '08-01', '09-01', '10-01', '11-01', '12-01'],\n",
    "#         title=None,\n",
    "#         highlight_years=[2001, 2015, 2023],\n",
    "#         plot_central_tendency_stats=True,\n",
    "#         quartile_shading=True,\n",
    "#         quartile_shading_alpha=0.4,\n",
    "#         quartile_shading_zorder=1,\n",
    "#         series_labels=True,\n",
    "#         series_alpha=1,\n",
    "#         group_by_decade=False,\n",
    "#         decade_stats_to_plot=\"All\",\n",
    "#         y_lower_lim=0,\n",
    "#         y_upper_lim=\"Auto\",\n",
    "#         legend='upper right',\n",
    "#         legend_ncol=1,\n",
    "#         input_start_year=2010,\n",
    "#         input_end_year=2020\n",
    "#     ):\n",
    "\n",
    "#         # if y_upper_lim == \"Auto\":\n",
    "#         #     y_upper_lim = self._ylim_max\n",
    "\n",
    "#         self._filter_dataframe(input_start_year, input_end_year)\n",
    "\n",
    "#         fig, ax = plt.subplots(figsize=(9, 7))\n",
    "\n",
    "#         if plot_central_tendency_stats:\n",
    "#             self._plot_central_tendency_stats(ax)\n",
    "\n",
    "#         if highlight_years:\n",
    "#             self._plot_highlight_years(ax, highlight_years)\n",
    "\n",
    "#         if quartile_shading:\n",
    "#             self._plot_quartile_shading(ax, quartile_shading_alpha, quartile_shading_zorder)\n",
    "\n",
    "#         if group_by_decade:\n",
    "#             self._plot_group_by_decade(ax, decade_stats_to_plot)\n",
    "#         else:\n",
    "#             self._plot_individual_series(ax, series_labels, series_alpha)\n",
    "\n",
    "#         self._set_plot_properties(ax, title, legend, legend_ncol, y_lower_lim, y_upper_lim)\n",
    "#         plt.show()\n",
    "\n",
    "#     def _filter_dataframe(self, start_year, end_year):\n",
    "#         self._df = self._df[(self._df['Year'] >= start_year) & (self._df['Year'] <= end_year)]\n",
    "#         self._unique_years = list(self._df['Year'].unique())\n",
    "#         self._start_year, self._end_year = self._unique_years[0], self._unique_years[-1]\n",
    "\n",
    "#     def _plot_central_tendency_stats(self, ax):\n",
    "#         self._mean.plot(ax=ax, label=\"Mean\", linestyle=':', color='black', linewidth=1.5, zorder=3)\n",
    "#         self._median.plot(ax=ax, label=\"Median\", linestyle=':', color='red', linewidth=1.5, zorder=3)\n",
    "\n",
    "#     def _plot_highlight_years(self, ax, highlight_years):\n",
    "#         for i, year in enumerate(highlight_years):\n",
    "#             self._pivot_table.loc[:, year].plot(ax=ax, linewidth=1.6, zorder=3, color=self._colors[i])\n",
    "\n",
    "#     def _plot_quartile_shading(self, ax, quartile_shading_alpha, quartile_shading_zorder):\n",
    "#         ax.fill_between(\n",
    "#             list(range(0, len(pd.DataFrame(self._mean).iloc[:, 0]))),\n",
    "#             pd.DataFrame(self._mean).iloc[:, 0].astype(float),\n",
    "#             pd.DataFrame(self._lower_bound_percentile25).iloc[:, 0].astype(float),\n",
    "#             where=(pd.DataFrame(self._mean).iloc[:, 0].astype(float) > pd.DataFrame(self._lower_bound_percentile25).iloc[:, 0].astype(float)),\n",
    "#             interpolate=True, color='yellow', alpha=quartile_shading_alpha, zorder=quartile_shading_zorder, label=\"q25-q75\")\n",
    "\n",
    "#         ax.fill_between(\n",
    "#             list(range(0, len(pd.DataFrame(self._mean).iloc[:, 0]))),\n",
    "#             pd.DataFrame(self._mean).iloc[:, 0].astype(float),\n",
    "#             pd.DataFrame(self._upper_bound_percentile75).iloc[:, 0].astype(float),\n",
    "#             where=(pd.DataFrame(self._mean).iloc[:, 0].astype(float) < pd.DataFrame(self._upper_bound_percentile75).iloc[:, 0].astype(float)),\n",
    "#             interpolate=True, color='yellow', alpha=quartile_shading_alpha, zorder=1)\n",
    "\n",
    "#     def _plot_group_by_decade(self, ax, decade_stats_to_plot):\n",
    "#         colors = ['blue', 'orange', 'purple', 'red']\n",
    "#         decade_groups = [list(range(i, i + 10)) for i in self._unique_decades]\n",
    "\n",
    "#         for i, decade in enumerate(decade_groups):\n",
    "#             means = self._pivot_table.loc[:, decade].mean(axis=1)\n",
    "#             medians = self._pivot_table.loc[:, decade].median(axis=1)\n",
    "#             self._plot_decade_stats_line(ax, means, medians, decade, i, colors, decade_stats_to_plot)\n",
    "\n",
    "#     def _plot_individual_series(self, ax, series_labels, series_alpha):\n",
    "#         filtered_pivot_table = self._get_filtered_pivot_table()\n",
    "#         if series_labels is False:\n",
    "#             for i in filtered_pivot_table.columns:\n",
    "#                 filtered_pivot_table[i].plot(ax=ax, alpha=series_alpha, zorder=2, linewidth=1.0, label='')\n",
    "#         else:\n",
    "#             filtered_pivot_table.plot(ax=ax, alpha=series_alpha, zorder=2, linewidth=1.0, label='')\n",
    "\n",
    "#     def _plot_decade_stats_line(self, ax, means, medians, decade, index, colors, decade_stats_to_plot):\n",
    "#         if decade_stats_to_plot == 'mean':\n",
    "#             means.plot(ax=ax, linestyle=\"--\", label=f\"mean {decade[0]} - {decade[-1]}\", linewidth=1, color=colors[index])\n",
    "#         elif decade_stats_to_plot == 'median':\n",
    "#             medians.plot(ax=ax, linestyle=\"-.\", label=f\"median {decade[0]} - {decade[-1]}\", linewidth=1, color=colors[index])\n",
    "#         else:\n",
    "#             means.plot(ax=ax, linestyle=\"--\", label=f\"mean {decade[0]} - {decade[-1]}\", linewidth=1, color=colors[index])\n",
    "#             medians.plot(ax=ax, linestyle=\"-.\", label=f\"median {decade[0]} - {decade[-1]}\", linewidth=1, color=colors[index])\n",
    "\n",
    "#     def _set_plot_properties(self, ax, title, legend, legend_ncol, y_lower_lim, y_upper_lim):\n",
    "#         if self._forced_x_positions is not None and self._forced_x_labels is not None:\n",
    "#             ax.set_xticks(self._forced_x_positions)\n",
    "#             xlim_min, xlim_max = self._forced_x_positions[0], self._forced_x_positions[-1]\n",
    "#             ax.set_xticklabels(self._forced_x_labels, rotation=45)\n",
    "#             ax.set_xlim([xlim_min, xlim_max])\n",
    "#             ax.set_ylim([y_lower_lim, y_upper_lim])\n",
    "\n",
    "#         plt.grid(color='green', linestyle=\":\", linewidth=0.5)\n",
    "#         plt.xlabel('Month-Day')\n",
    "#         plt.ylabel('Lake Elevation (ft)')\n",
    "#         plt.legend(loc=legend, ncol=legend_ncol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b4b6e0-7cc0-47f0-97e4-c0c85594be3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#import os\n",
    "#import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import calendar\n",
    "from scipy.integrate import trapz\n",
    "from collections import OrderedDict\n",
    "\n",
    "class StackedLinePlotOriginal:\n",
    "    def __init__(self, data, name_of_date_column, name_of_Q_column):\n",
    "        \n",
    "        # self.csv_path = data\n",
    "        self._df = None  # Initialize to None\n",
    "        self.name_of_date_column = name_of_date_column  # Store the column name\n",
    "        self.name_of_Q_column = name_of_Q_column  # Store the column name\n",
    "        self._data = data\n",
    "        self._pivot_table = None\n",
    "        self._name_of_Q_column = name_of_Q_column\n",
    "        self._forced_x_positions = None\n",
    "        self._forced_x_labels = None\n",
    "        self._mean = None\n",
    "        self._median = None\n",
    "        self._st_dev = None\n",
    "        self._lower_bound = None\n",
    "        self._upper_bound = None\n",
    "        self._lower_bound_percentile25 = None\n",
    "        self._upper_bound_percentile75 = None\n",
    "        self._colors = ['crimson', 'springgreen', 'dodgerblue', 'purple', 'green', 'deeppink', 'lawngreen', 'coral', 'lime', 'navy', 'goldenrod']\n",
    "\n",
    "    @property\n",
    "    def df(self):\n",
    "        return self._df\n",
    "\n",
    "    @df.setter\n",
    "    def df(self, data):\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            print(\"Data is a dataframe.\")\n",
    "            self._df = data.copy()  # Set the DataFrame directly\n",
    "        elif isinstance(data, str):\n",
    "            try:\n",
    "                print(\"csv\")\n",
    "                self._df = pd.read_csv(data)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading CSV file: {e}\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"Invalid input type. Please provide either a pandas DataFrame or a CSV file path.\")\n",
    "            return\n",
    "        self._df['Date'] = pd.to_datetime(self._df[self.name_of_date_column])\n",
    "        self._df['month'] = self._df['Date'].dt.month\n",
    "        self._df['Year'] = self._df['Date'].dt.year\n",
    "        self._df['month-day'] = self._df['Date'].apply(lambda x: x.strftime('%m-%d'))\n",
    "\n",
    "    def _create_pivot_table(self):\n",
    "        if self._df is not None:\n",
    "            self._df.pivot(index=\"month-day\", columns='Year', values=self._name_of_Q_column)\n",
    "        return self._pivot_table\n",
    "\n",
    "    @property\n",
    "    def MeanValue(self):\n",
    "        if self._mean_value is None:\n",
    "            self.calculate_statistics()\n",
    "        return self._mean_value\n",
    "\n",
    "    @property\n",
    "    def MonthlyStats(self):\n",
    "        monthly_stats = self._monthly_stats\n",
    "        monthly_stats.index = monthly_stats.index.map(lambda x: calendar.month_name[x])\n",
    "        monthly_stats = monthly_stats.round(1)\n",
    "        return monthly_stats\n",
    "\n",
    "    @property\n",
    "    def Stats(self):\n",
    "        return self._df_stat_summary.round(2)\n",
    "\n",
    "    def calculate_statistics(self):\n",
    "        self._stats = self._df.groupby(\"month-day\")[self._name_of_Q_column].agg(['mean','median', 'std', (\"q25\", lambda x: x.quantile(0.25)),(\"q75\", lambda y: y.quantile(0.75))])\n",
    "        self._monthly_stats = self._df.groupby(\"month\")[self._name_of_Q_column].agg(['mean','median', 'std', (\"q25\", lambda x: x.quantile(0.25)),(\"q75\", lambda y: y.quantile(0.75))])\n",
    "        self._mean = self._stats.iloc[:,0]\n",
    "        self._median = self._stats.iloc[:,1]\n",
    "        self._st_dev = self._stats.iloc[:,2]\n",
    "        self._percentile25 = self._stats.iloc[:,3]\n",
    "        self._percentile75 = self._stats.iloc[:,4]\n",
    "        self._lower_bound = self._mean - self._st_dev\n",
    "        self._upper_bound = self._mean + self._st_dev\n",
    "        self._lower_bound_percentile25 = self._mean - self._percentile25\n",
    "        self._upper_bound_percentile75 = self._mean + self._percentile75\n",
    "\n",
    "    def calculate_yearly_volumes(self):\n",
    "        years = []\n",
    "        area = []\n",
    "        for year in self._pivot_table.columns:\n",
    "            dates = (list(range(0, len(self._pivot_table[year].dropna()))))\n",
    "            area.append(trapz(self._pivot_table[year].dropna(), dates))\n",
    "            years.append(year)\n",
    "        area_dict = OrderedDict()\n",
    "        for key, value in zip(years, area):\n",
    "            area_dict[key] = value\n",
    "        return area_dict\n",
    "\n",
    "    def plotStackedLinePlot(self, forced_x_positions=[1, 32, 60, 91, 121, 152, 182, 213, 244, 274, 305, 336],\n",
    "                             forced_x_labels=['01-01', '02-01', '03-01', '04-01', '05-01', '06-01', '07-01', '08-01', '09-01', '10-01', '11-01', '12-01'],\n",
    "                             title=None, highlight_years=[2001, 2015, 2023], plot_central_tendency_stats=True,\n",
    "                             quartile_shading=True, quartile_shading_alpha=0.4, quartile_shading_zorder=1,\n",
    "                             series_labels=True, series_alpha=1, group_by_decade=False, decade_stats_to_plot=\"All\",\n",
    "                             y_lower_lim=0, y_upper_lim=\"True\", legend='upper right', legend_ncol=1,\n",
    "                             input_start_year=2010, input_end_year=2020):\n",
    "\n",
    "        # if y_upper_lim == \"Auto\":\n",
    "        #     y_upper_lim = self._ylim_max\n",
    "\n",
    "        self._df = self._df[(self._df['Year'] >= input_start_year) & (self._df['Year'] <= input_end_year)]\n",
    "        self._unique_years = list(self._df['Year'].unique())\n",
    "        self._start_year = self._unique_years[0]\n",
    "        self._end_year = self._unique_years[-1]\n",
    "        self._num_of_decades = math.ceil((self._end_year - self._start_year) / 10)\n",
    "        self._unique_decades = list(self._df['Year'].apply(lambda year: (year // 10) * 10).unique())\n",
    "        self._forced_x_positions = forced_x_positions\n",
    "        self._forced_x_labels = forced_x_labels\n",
    "        self.input_start_year = input_start_year\n",
    "        self.input_end_year = input_end_year\n",
    "        self.calculate_statistics()\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(9, 7))\n",
    "\n",
    "        if plot_central_tendency_stats == True:\n",
    "            self._mean.plot(ax=ax, label=\"Mean\", linestyle=':', color='black', linewidth=1.5, zorder=3)\n",
    "            self._median.plot(ax=ax, label=\"Median\", linestyle=':', color='red', linewidth=1.5, zorder=3)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if highlight_years:\n",
    "            for i, year in enumerate(highlight_years):\n",
    "                self._pivot_table.loc[:, year].plot(ax=ax, linewidth=1.6, zorder=3, color=self._colors[i])\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        if quartile_shading == True:\n",
    "            plt.fill_between(\n",
    "                list(range(0, len(pd.DataFrame(self._mean).iloc[:, 0]))),\n",
    "                pd.DataFrame(self._mean).iloc[:, 0].astype(float),\n",
    "                pd.DataFrame(self._lower_bound).iloc[:, 0].astype(float),\n",
    "                where=(pd.DataFrame(self._mean).iloc[:, 0].astype(float) > pd.DataFrame(self._lower_bound_percentile25).iloc[:, 0].astype(float)),\n",
    "                interpolate=True, color='yellow', alpha=quartile_shading_alpha, zorder=quartile_shading_zorder, label=\"q25-q75\")\n",
    "\n",
    "            plt.fill_between(\n",
    "                list(range(0, len(pd.DataFrame(self._mean).iloc[:, 0]))),\n",
    "                pd.DataFrame(self._mean).iloc[:, 0].astype(float),\n",
    "                pd.DataFrame(self._upper_bound).iloc[:, 0].astype(float),\n",
    "                where=(pd.DataFrame(self._mean).iloc[:, 0].astype(float) < pd.DataFrame(self._upper_bound_percentile75).iloc[:, 0].astype(float)),\n",
    "                interpolate=True, color='yellow', alpha=quartile_shading_alpha, zorder=1)\n",
    "\n",
    "        if group_by_decade == True:\n",
    "            decade_groups = []\n",
    "\n",
    "            for i in self._unique_decades:\n",
    "                decade_groups.append(list(range(i, i + 10)))\n",
    "\n",
    "            if len(decade_groups) == 1:\n",
    "                start_year_index = decade_groups[0].index(self.input_start_year)\n",
    "                end_year_index = decade_groups[0].index(self.input_end_year)\n",
    "                decade_groups[0] = decade_groups[0][start_year_index:end_year_index + 1]\n",
    "            else:\n",
    "                start_year_index = decade_groups[0].index(self.input_start_year)\n",
    "                decade_groups[0] = decade_groups[0][start_year_index:]\n",
    "\n",
    "                end_group = list(range(decade_groups[-1][0], self.input_end_year + 1))\n",
    "                decade_groups[-1] = end_group\n",
    "\n",
    "            colors = ['blue', 'orange', 'purple', 'red']\n",
    "            for i, decade in enumerate(decade_groups):\n",
    "                decadeDF = self._pivot_table.loc[:, decade]\n",
    "                means = decadeDF[decadeDF.columns].mean(axis=1)\n",
    "                medians = decadeDF[decadeDF.columns].median(axis=1)\n",
    "                if decade_stats_to_plot == 'mean':\n",
    "                    means.plot(ax=ax, linestyle=\"--\", label=\"mean {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "                elif decade_stats_to_plot == 'median':\n",
    "                    medians.plot(ax=ax, linestyle=\"-.\", label=\"median {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "                else:\n",
    "                    means.plot(ax=ax, linestyle=\"--\", label=\"mean {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "                    medians.plot(ax=ax, linestyle=\"-.\", label=\"median {} - {}\".format(decade[0], decade[-1]), linewidth=1, color=colors[i])\n",
    "\n",
    "        else:\n",
    "            if highlight_years:\n",
    "                filtered_years = [year for year in self._pivot_table.columns if year not in highlight_years]\n",
    "                filtered_pivot_table = self._pivot_table.loc[:, filtered_years]\n",
    "            else:\n",
    "                filtered_pivot_table = self._pivot_table\n",
    "\n",
    "            if series_labels == False:\n",
    "                for i in filtered_pivot_table.columns:\n",
    "                    filtered_pivot_table[i].plot(ax=ax, alpha=series_alpha, zorder=2, linewidth=1.0, label='')\n",
    "            else:\n",
    "                filtered_pivot_table.plot(ax=ax, alpha=series_alpha, zorder=2, linewidth=1.0, label='')\n",
    "\n",
    "        if self._forced_x_positions is not None and self._forced_x_labels is not None:\n",
    "            ax.set_xticks(self._forced_x_positions)\n",
    "            xlim_min = self._forced_x_positions[0]\n",
    "            xlim_max = self._forced_x_positions[-1]\n",
    "            ax.set_xticklabels(self._forced_x_labels, rotation=45)\n",
    "            ax.set_xlim([xlim_min, xlim_max])\n",
    "            ax.set_ylim([y_lower_lim, y_upper_lim])\n",
    "\n",
    "        plt.grid(color='green', linestyle=\":\", linewidth=0.5)\n",
    "        plt.xlabel('Month-Day')\n",
    "        plt.ylabel('Lake Elevation (ft)')\n",
    "        plt.title(title)\n",
    "\n",
    "        if legend == \"partial\":\n",
    "            plt.legend(loc='upper right', ncol=legend_ncol, labels=['Mean', 'Median'])\n",
    "\n",
    "        else:\n",
    "            plt.legend(loc=legend, ncol=legend_ncol)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"-------This module creates customized StackedLinePlots.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
